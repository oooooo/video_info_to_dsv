
import torch
import os
from dotenv import load_dotenv
from pydub import AudioSegment
import whisper
from . import _dir
from . import _utils


# æ”¯æ´å‰¯æª”å
AUDIO_EXTS = (".wav", ".mp3", ".m4a", ".flac")

# æ¯æ®µ 5 åˆ†é˜
SEGMENT_MS = 5 * 60 * 1000

# Whisper æ¨¡å‹
# model = whisper.load_model("medium")  # å¯æ”¹ medium/base/small


def load_whisper_model(model_size="medium"):
    """
    è¼‰å…¥ Whisper æ¨¡å‹ï¼Œæ ¹æ“šç’°å¢ƒè‡ªå‹•åˆ¤æ–·æ˜¯å¦å•Ÿç”¨ GPU / FP16ã€‚
    """
    if torch.cuda.is_available():
        print(":: --- åµæ¸¬åˆ° GPUï¼Œå¯ä½¿ç”¨ FP16 æ¨¡å¼")
        model = whisper.load_model(model_size).to("cuda")
        use_fp16 = True
    else:
        print(":: --- æœªåµæ¸¬åˆ° GPUï¼Œè‡ªå‹•åˆ‡æ›è‡³ CPU æ¨¡å¼ (fp16=False)")
        model = whisper.load_model(model_size, device="cpu")
        use_fp16 = False
    return model, use_fp16


def segments_to_srt(segments, srt_path):
    """è™•ç†éŸ³è¨Šç‰‡æ®µ SRT"""

    def format_timestamp(seconds):
        h = int(seconds // 3600)
        m = int((seconds % 3600) // 60)
        s = int(seconds % 60)
        ms = int((seconds - int(seconds)) * 1000)
        return f"{h:02}:{m:02}:{s:02},{ms:03}"

    with open(srt_path, "w", encoding="utf-8") as f:
        for idx, seg in enumerate(segments, start=1):
            start = format_timestamp(seg["start"])
            end = format_timestamp(seg["end"])
            text = seg["text"].strip()
            f.write(f"{idx}\n{start} --> {end}\n{text}\n\n")


def transcribe_audio(add_txt=False):
    print(":: ğŸ™‰ éŸ³è¨Šè½‰å­—å¹•ï¼š")
    """éŸ³æª”åˆ†æ®µ + Whisper è½‰éŒ„ + ç”Ÿæˆ SRT"""

    model, use_fp16 = load_whisper_model()

    pending = _utils.list_files(_dir.AUDIO_DIR, AUDIO_EXTS)
    if not pending:
        print(f":: âš ï¸ {_dir.AUDIO_DIR} æ²’æœ‰å¾…è™•ç†æª”æ¡ˆ")
        return

    for file in pending:
        filepath = os.path.join(_dir.AUDIO_DIR, file)
        filename = os.path.splitext(file)[0]

        print(f":: process {file}")
        # è¼‰å…¥éŸ³è¨Šæª”ï¼Œè®Šæˆå¯ä»¥åœ¨ Python è£¡æ“ä½œçš„éŸ³è¨Šç‰©ä»¶
        audio = AudioSegment.from_file(filepath)
        segments_all = []

        # éŸ³è¨Šåˆ†æ®µ
        for i in range(0, len(audio), SEGMENT_MS):
            # len(audio) éŸ³æª”çš„é•·åº¦ï¼ˆæ¯«ç§’, msï¼‰
            # å¾ i å–åˆ° i+SEGMENT_MS æ¯«ç§’ã€‚
            seg = audio[i:i+SEGMENT_MS]
            seg_file = "temp_seg.wav"
            seg_path = os.path.join(_dir.AUDIO_DIR, seg_file)
            seg.export(seg_path, format="wav")

            # çµ¦ Whisper è½‰éŒ„
            # result = model.transcribe(seg_file, language="Chinese")
            result = model.transcribe(
                seg_path, language="Chinese", fp16=use_fp16)

            """ result = {
                "text": "ä½ å¥½ æˆ‘æ˜¯æ¸¬è©¦",
                "segments": [
                    {"start":0.0, "end":3.2, "text":"ä½ å¥½"},
                    {"start":3.2, "end":6.5, "text":"æˆ‘æ˜¯æ¸¬è©¦"}
                ],
                "language": "zh"
            }
            """
            segments_all.extend(result["segments"])
            # extend() æŠŠå¯è¿­ä»£ç‰©ä»¶çš„æ¯å€‹å…ƒç´ ã€Œæ‹†é–‹ã€ã€ã€Œé€å€‹åŠ å…¥ã€ list
            os.remove(seg_path)

        # ç”Ÿæˆ SRT å­—å¹•
        srt_path = os.path.join(_dir.TRANS_DIR, f"{filename}.srt")
        segments_to_srt(segments_all, srt_path)
        # print(f":: SRT å®Œæˆ {srt_path}")

        # é¸æ“‡æ€§ç”Ÿæˆ TXT ï¼ˆin TRANS_DIRï¼‰
        if add_txt:
            txt_path = os.path.join(_dir.TRANS_DIR, f"{filename}.txt")
            full_text = "\n".join([seg["text"] for seg in segments_all])
            # å¯«å…¥æª”æ¡ˆ (è¦†è“‹)
            with open(txt_path, "w", encoding="utf-8") as f:
                f.write(full_text.strip())
            # print(f":: TXT å®Œæˆ {txt_path}")

        # è™•ç†å®Œç§»å‹•æª”æ¡ˆ
        _utils.move_file(filepath, os.path.join(_dir.FINISH_DIR, file))


def srt_to_txt(srt_dir):
    """
    å°‡ TRANS_DIR ä¸‹çš„æ‰€æœ‰ SRT è½‰æˆ TXT
    srt_dir: SRT æ‰€åœ¨è³‡æ–™å¤¾
    """
    for file in os.listdir(srt_dir):
        if not file.lower().endswith(".srt"):
            continue
        srt_path = os.path.join(srt_dir, file)
        txt_path = os.path.join(srt_dir, f"{os.path.splitext(file)[0]}.txt")
        with open(srt_path, "r", encoding="utf-8") as f:
            # åˆ—è¡¨ç”Ÿæˆå¼ [è¡¨é”å¼ for è®Šæ•¸ in å¯è¿­ä»£ç‰©ä»¶ if æ¢ä»¶]
            # ä¸æ˜¯æœ‰ "-->" é‚£è¡Œ / ä¸æ˜¯ç©ºè¡Œ line.strip() / é€™è¡Œä¸æ˜¯ å…¨æ•¸å­—
            lines = [
                line.strip()
                for line in f.readlines()
                if "-->" not in line and line.strip() and not line.isdigit()
            ]

        # å¯«å…¥/è¦†è“‹
        with open(txt_path, "w", encoding="utf-8") as f:
            f.write(" ".join(lines))
        print(f":: å¾ SRT ç”Ÿæˆ TXT {txt_path}")
